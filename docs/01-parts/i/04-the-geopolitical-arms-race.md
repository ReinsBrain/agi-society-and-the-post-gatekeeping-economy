<a id="i.04" class="chapter page-break"></a>

## Chapter 4 — The Geopolitical Arms Race

### Why Slowing AI Development Is Not a Neutral Option

In an ideal world, societies could collectively agree to “slow down” AGI development until governance, safety, and economic adaptation catch up. In the real world, however, strategic technologies rarely permit that kind of pause. When the capability at stake is not merely a weapon but a general-purpose amplifier of intelligence—research, cyber operations, persuasion, industrial design, logistics, and military planning—**delay becomes a competitive choice**.

If one bloc meaningfully slows while another continues, the slower bloc does not preserve a stable status quo. It risks creating a widening capability gap that compounds over time. Unlike many industrial advantages, AGI advantage is self-reinforcing: better systems accelerate scientific discovery and engineering; those advances feed back into better systems; and the lead becomes harder to close.

This is why “restraint” is not symmetric. A unilateral slowdown can be interpreted—by adversaries and even by allies—as forfeiture of strategic ground. Even a well-intentioned regulatory regime can function as a self-imposed handicap if it suppresses domestic experimentation while foreign ecosystems operate with fewer constraints.

At the same time, racing blindly is also not neutral. Unchecked acceleration increases the probability of catastrophic error, misuse, and destabilization. The core geopolitical dilemma, then, is not “race or pause,” but how to pursue capability while preventing a small number of actors—domestic or foreign—from turning that capability into unilateral coercive power.

### The East–West Competition and Asymmetric Risks

The competition that matters is not only between two countries; it is increasingly a contest between networks—alliances, supply chains, standards bodies, capital markets, and information ecosystems. The East–West schism is characterized by different assumptions about transparency, individual rights, state authority, and the relationship between citizens and institutions.

This creates asymmetric risks.

First, systems built under tighter state integration may be deployed more rapidly across society, because friction is lower: fewer veto points, faster coordination, and greater tolerance for surveillance or centralized enforcement. Even if such deployment reduces internal dissent, it can produce formidable external leverage.

Second, regimes with lower tolerance for domestic pluralism may be more willing to accept international backlash in exchange for strategic advantage. Where liberal democracies often face internal constraint—courts, media scrutiny, electoral cycles—more centralized systems can pursue long-horizon strategies with fewer internal interruptions.

Third, influence operations scale with intelligence tools. AGI is not only a factory or a lab; it is a persuasion engine. As model capability improves, so does the ability to generate targeted narratives, impersonate legitimate voices, saturate discourse, and exploit social fissures. Democracies are particularly exposed to these dynamics because their legitimacy depends on shared epistemic ground.

The implication is not that “the West must become authoritarian to compete.” It is that **open societies must be realistic about the forms of competition they face**, and must design resilience into both their technology and their institutions.

### How Dominance in AGI Translates to Coercive Power

The most important consequence of AGI dominance is not that one bloc becomes richer. It is that dominance can be converted into *coercive leverage* across multiple layers of society.

At the economic layer, a dominant AGI platform can become a global dependency. If critical industries, healthcare systems, financial infrastructure, education platforms, or government services rely on a small set of proprietary intelligence systems, then access control becomes a geopolitical tool. Denial of service, price shocks, licensing restrictions, or embedded policy constraints can all function as levers of power.

At the security layer, advanced AI amplifies cyber offense and defense. It accelerates vulnerability discovery, exploit generation, social engineering, and automated reconnaissance, while also strengthening defensive monitoring and anomaly detection. The side with superior capability may gain disproportionate advantage not only in war but in continuous gray-zone operations.

At the industrial layer, AGI accelerates R&D and optimizes complex systems—semiconductors, materials, energy grids, logistics, weapons development, and space systems. Advantage here is compounding: it improves the ability to build the next generation of the very tools that produce advantage.

At the cultural and political layer, AGI can erode trust. Deepfakes, synthetic media, and automated influence campaigns can make basic verification costly and contested. When citizens cannot agree on what is real, democratic coordination degrades. In that environment, the most “stable” systems—whether corporate platforms or centralized states—gain relative power.

This is the geopolitical mirror of the economic story told in Parts I.1 through I.3: when people and institutions become dependent on centralized intelligence, they become governable by whoever controls it.

### A Transition Constraint: We Must Compete While We Decentralize

These dynamics create a practical constraint on any ideal future architecture. A purely “slow and deliberate” plan is not viable if it concedes strategic advantage. Yet a purely “move fast and centralize” plan hardens the very gatekeeping failure mode this document aims to avoid.

The path forward must therefore do two things at once:

1. **Support rapid capability development within open societies**, so that they remain competitive in scientific, economic, and security terms.

2. **Prevent that capability from collapsing into a small number of domestic choke points**, by designing for federation, portability, and plural ownership from the beginning.

In other words, the goal is not only to build strong AI, but to build it in a way that preserves the political character of the societies that develop it. The remainder of this document argues that federated architectures, distributed expert stewardship, and interoperability-based governance offer a route to that end—one that can sustain competition without accepting centralized control as the inevitable price of victory.

---
